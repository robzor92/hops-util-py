{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `hops-util-py` Integration Tests\n",
    "\n",
    "This notebook can be converted to a python file and submitted as a spark job for integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import experiment, hdfs, tensorboard, devices, kafka, featurestore, tls, util, serving, constants\n",
    "import stat\n",
    "import os\n",
    "import shutil\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, IntegerType, FloatType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from pyspark.sql import DataFrame\n",
    "from petastorm.unischema import dict_to_spark_row, Unischema, UnischemaField\n",
    "from petastorm.codecs import ScalarCodec, CompressedImageCodec, NdarrayCodec\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "from confluent_kafka import Producer, Consumer, KafkaError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment API Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_asserts():\n",
    "    from hops import tensorboard\n",
    "    from hops import devices\n",
    "    from hops import hdfs\n",
    "    import os\n",
    "    assert tensorboard.logdir() != None\n",
    "    assert devices.get_num_gpus() >= 0\n",
    "    assert hdfs.project_path() == hdfs.project_path(hdfs.project_name())\n",
    "    if tensorboard.local_logdir_bool:\n",
    "        assert \"hdfs://\" not in tensorboard.logdir()\n",
    "        assert os.path.exists(tensorboard.logdir())\n",
    "    else:\n",
    "        assert \"hdfs://\" in tensorboard.logdir()\n",
    "        assert hdfs.exists(tensorboard.logdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_ret():\n",
    "    exp_asserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_ret_params(a, b):\n",
    "    exp_asserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_no_name():\n",
    "    exp_asserts()\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_no_name_params(a, b):\n",
    "    exp_asserts()\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_path():\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_path_params(a, b):\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_val():\n",
    "    exp_asserts()\n",
    "    return {'value': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_val_params(a, b):\n",
    "    exp_asserts()\n",
    "    return {'value': a+b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ret():\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'value': 10, 'morevals': 0.5, 'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ret_params(a, b):\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'value': a+b, 'morevals': b, 'logfile': 'testfile.txt', 'diagram': 'img.png'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_return_values(logdir, hp_dict, should_return_hp_dict, return_dict, should_return_return_dict):\n",
    "    assert hdfs.exists(logdir)\n",
    "    \n",
    "    if should_return_hp_dict:\n",
    "        assert type(hp_dict) == dict\n",
    "        \n",
    "    if should_return_return_dict:\n",
    "        assert type(return_dict) == dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_best_hyperparameters(return_dict, best_hyperparameters):\n",
    "    for key in best_hyperparameters.keys():\n",
    "        assert float(best_hyperparameters[key]) == float(return_dict[key]), '{} not equal to {}'.format(best_hyperparameters[key], return_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_return_dict(logdir, return_dict):\n",
    "    return_dict_contents = hdfs.load(logdir + '/.return')\n",
    "    logdir_return_dict = json.loads(return_dict_contents)\n",
    "    assert return_dict == logdir_return_dict, 'dics are not the same {} - {}'.format(return_dict, logdir_return_dict)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test `experiment.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/experiment.py\", line 108, in launch\n",
      "    logdir, return_dict = launcher._run(sc, map_fun, run_id, args_dict, local_logdir)\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hops import experiment\n",
    "params={'a': [-5, 4.9], 'b': [-8, 10.3]}\n",
    "\n",
    "logdir, return_dict = experiment.launch(no_ret, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(no_ret, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "                     \n",
    "logdir, return_dict = experiment.launch(no_ret_params, params, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "                     \n",
    "logdir, return_dict = experiment.launch(no_ret_params, params, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_no_name, local_logdir=False, name='some custom name')\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "                     \n",
    "logdir, return_dict = experiment.launch(single_ret_no_name, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "                     \n",
    "logdir, return_dict = experiment.launch(single_ret_no_name_params, params, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_no_name_params, params, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_path, local_logdir=False, description='some custom desc')\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_path, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_path_params, params, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_path_params, params, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_val, local_logdir=False, name='some custom name', description='some custom desc')\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_val, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_val_params, params, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_val_params, params, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(multi_ret, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(multi_ret, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(multi_ret_params, params, local_logdir=False)\n",
    "assert_return_values(logdir, None, False, return_dict, True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(multi_ret_params, params, local_logdir=True)\n",
    "assert_return_values(logdir, None, False, return_dict, True)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.random_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_41?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_41?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_42?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_42?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_43?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_43?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_44?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_44?xattr=REPLACE\n",
      "<Response [200]>"
     ]
    }
   ],
   "source": [
    "params={'a': [-5, 4.9], 'b': [-8, 10.3]}\n",
    "try:\n",
    "    experiment.grid_search(no_ret_params, params)\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.grid_search(multi_ret_params, params)\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_no_name_params, params, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_no_name_params, params, local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_val_params, params, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_val_params, params, local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(multi_ret_params, params, local_logdir=False, direction='min', optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, metric = experiment.grid_search(multi_ret_params, params, local_logdir=True, direction='max', optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "params={'a': [-1, 1.5], 'b': [-1.5, 1]}\n",
    "\n",
    "# Make sure minimization work\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_no_name_params, params, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': -1, 'b': -1.5})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "# Make sure maximization work\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_no_name_params, params, local_logdir=True, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': 1.5, 'b': 1})\n",
    "assert_return_dict(logdir, return_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.random_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_10?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_10?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_11?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_11?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_12?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_12?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_13?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_13?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_14?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_14?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_15?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_15?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_16?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_16?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_17?xattr=CREATE\n",
      "<Response [200]>\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_17?xattr=REPLACE\n",
      "<Response [200]>"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment.random_search(no_ret_params, params, samples=2)\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.random_search(multi_ret_params, params, samples=2)\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_no_name_params, params, samples=2, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_no_name_params, params, samples=2, local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_val_params, params, samples=2, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_val_params, params, samples=2, local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(multi_ret_params, params, samples=2, local_logdir=False, direction='max', optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(multi_ret_params, params, samples=2, local_logdir=True, direction='min', optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.differential_evolution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_18?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_18?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_19?xattr=CREATE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_19?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_20?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: -0.8333333333333334, best metric: -6.0, best parameter combination: ['a=-3', 'b=-3']\n",
      "\n",
      "Generation 2 || average metric: -5.0, best metric: -9.0, best parameter combination: ['a=-3', 'b=-6']\n",
      "\n",
      "Generation 3 || average metric: -6.333333333333333, best metric: -9.0, best parameter combination: ['a=-3', 'b=-6']\n",
      "\n",
      "Generation 4 || average metric: -7.5, best metric: -11.0, best parameter combination: ['a=-4', 'b=-7']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_20?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_21?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: 1.1666666666666667, best metric: 13.0, best parameter combination: ['a=4', 'b=9']\n",
      "\n",
      "Generation 2 || average metric: 4.666666666666667, best metric: 13.0, best parameter combination: ['a=4', 'b=9']\n",
      "\n",
      "Generation 3 || average metric: 10.166666666666666, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Generation 4 || average metric: 13.166666666666666, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_21?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_22?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: -0.3333333333333333, best metric: -11.0, best parameter combination: ['a=-4', 'b=-7']\n",
      "\n",
      "Generation 2 || average metric: -3.1666666666666665, best metric: -11.0, best parameter combination: ['a=-4', 'b=-7']\n",
      "\n",
      "Generation 3 || average metric: -8.333333333333334, best metric: -13.0, best parameter combination: ['a=-5', 'b=-8']\n",
      "\n",
      "Generation 4 || average metric: -8.666666666666666, best metric: -13.0, best parameter combination: ['a=-5', 'b=-8']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_22?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_23?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: 2.1666666666666665, best metric: 9.0, best parameter combination: ['a=3', 'b=6']\n",
      "\n",
      "Generation 2 || average metric: 4.333333333333333, best metric: 9.0, best parameter combination: ['a=3', 'b=6']\n",
      "\n",
      "Generation 3 || average metric: 5.0, best metric: 9.0, best parameter combination: ['a=3', 'b=6']\n",
      "\n",
      "Generation 4 || average metric: 7.0, best metric: 11.0, best parameter combination: ['a=3', 'b=8']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_23?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_24?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: 4.666666666666667, best metric: 12.0, best parameter combination: ['a=5', 'b=7']\n",
      "\n",
      "Generation 2 || average metric: 9.333333333333334, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Generation 3 || average metric: 11.333333333333334, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Generation 4 || average metric: 13.333333333333334, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_24?xattr=REPLACE\n",
      "<Response [200]>\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_25?xattr=CREATE\n",
      "<Response [200]>\n",
      "Generation 1 || average metric: -2.0, best metric: -7.0, best parameter combination: ['a=4', 'b=-7']\n",
      "\n",
      "Generation 2 || average metric: -4.666666666666667, best metric: -7.0, best parameter combination: ['a=4', 'b=-7']\n",
      "\n",
      "Generation 3 || average metric: -7.0, best metric: -8.0, best parameter combination: ['a=0', 'b=-8']\n",
      "\n",
      "Generation 4 || average metric: -7.666666666666667, best metric: -8.0, best parameter combination: ['a=-5', 'b=-8']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "/hopsworks-api/api/project/120/experiments/application_1565768877650_0025_25?xattr=REPLACE\n",
      "<Response [200]>"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment.differential_evolution(no_ret_params, params)\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.differential_evolution(multi_ret_params, params)\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_no_name_params, params, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_no_name_params, params, local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_val_params, params, local_logdir=True, direction='min')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_val_params, params,local_logdir=False, direction='max')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(multi_ret_params, params, local_logdir=False, direction='max', optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(multi_ret_params, params, local_logdir=True, direction='min', optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Distributed Training `experiment.collective_all_reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HopsFS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test HopsFS operations\n",
    "\n",
    "- `hdfs.project_user()`\n",
    "- `hdfs.project_name()`\n",
    "- `hdfs.project_path()`\n",
    "- `hdfs.exists()`\n",
    "- `hdfs.load()`\n",
    "- `hdfs.copy_to_hdfs()`\n",
    "- `hdfs.copy_to_local()`\n",
    "- `hdfs.ls()`\n",
    "- `hdfs.lsl()`\n",
    "- `hdfs.glob()`\n",
    "- `hdfs.cp()`\n",
    "- `hdfs.rmr()`\n",
    "- `hdfs.rename()`\n",
    "- `hdfs.stat()`\n",
    "- `hdfs.isdir()`\n",
    "- `hdfs.isfile()`\n",
    "- `hdfs.add_module()`\n",
    "- `hdfs.delete()`\n",
    "- `hdfs.get_plain_path()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_user = hdfs.project_user()\n",
    "project_name = hdfs.project_name()\n",
    "assert project_name in project_user\n",
    "project_path = hdfs.project_path()\n",
    "assert project_name in project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README = hdfs.load(\"Logs/README.md\")\n",
    "assert len(logs_README) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.dump(\"test\", \"Logs/README_dump_test.md\")\n",
    "assert hdfs.exists(\"Logs/README_dump_test.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README_dumped = hdfs.load(\"Logs/README_dump_test.md\")\n",
    "assert logs_README_dumped.decode(\"utf-8\") == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources/upload.txt\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs file relative path\n",
    "\n",
    "with open('upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\")\n",
    "assert hdfs.exists(\"Resources/upload.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload.txt\")\n",
    "assert \"first upload\" == hdfs_copied_file.decode(\"utf-8\"), \"first content does not match\"\n",
    "\n",
    "with open('upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\", overwrite=True)\n",
    "assert hdfs.exists(\"Resources/upload.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload.txt\")\n",
    "assert \"second upload\" == hdfs_copied_file.decode(\"utf-8\"), \"second content does not match\"\n",
    "\n",
    "try:\n",
    "    hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\")\n",
    "    assert False\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "hdfs.rmr(\"Resources/upload.txt\")\n",
    "os.remove(\"upload.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources/upload_absolute.txt\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs file absolute path\n",
    "\n",
    "with open('upload_absolute.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_absolute.txt\", \"Resources\")\n",
    "assert hdfs.exists(\"Resources/upload_absolute.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_absolute.txt\")\n",
    "assert \"first upload\" == hdfs_copied_file.decode(\"utf-8\"), \"first content does not match\"\n",
    "\n",
    "with open('upload_absolute.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_absolute.txt\", \"Resources\", overwrite=True)\n",
    "assert hdfs.exists(\"Resources/upload_absolute.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_absolute.txt\")\n",
    "assert \"second upload\" == hdfs_copied_file.decode(\"utf-8\"), \"second content does not match\"\n",
    "\n",
    "try:\n",
    "    hdfs.copy_to_hdfs(\"upload_absolute.txt\", \"Resources\")\n",
    "    assert False\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "hdfs.rmr(\"Resources/upload_absolute.txt\")\n",
    "os.remove(\"upload_absolute.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path upload_dir to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload_dir to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources/upload_dir\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs directory relative path\n",
    "\n",
    "if not os.path.exists(\"upload_dir\"):\n",
    "    os.mkdir(\"upload_dir\")\n",
    "\n",
    "assert not hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(\"upload_dir\", \"Resources\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "\n",
    "with open('upload_dir/upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(\"upload_dir\", \"Resources\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "\n",
    "shutil.rmtree(\"upload_dir\")\n",
    "hdfs.rmr(\"Resources/upload_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/upload_dir_absolute to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/upload_dir_absolute to hdfs path hdfs://10.0.2.15:8020/Projects/collect/Resources/upload_dir_absolute\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs directory absolute path\n",
    "\n",
    "if not os.path.exists(\"upload_dir_absolute\"):\n",
    "    os.mkdir(\"upload_dir_absolute\")\n",
    "    \n",
    "assert not hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_dir_absolute\", \"Resources\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir_absolute/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "\n",
    "with open('upload_dir_absolute/upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_dir_absolute\", \"Resources\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir_absolute/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "\n",
    "shutil.rmtree(\"upload_dir_absolute\")\n",
    "hdfs.rmr(\"Resources/upload_dir_absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "File hdfs://10.0.2.15:8020/Projects/collect/Resources/somefile.txt is already localized, skipping download...\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "File hdfs://10.0.2.15:8020/Projects/collect/Resources/somefile.txt is already localized, skipping download..."
     ]
    }
   ],
   "source": [
    "#copy_to_local file\n",
    "\n",
    "# Download first time\n",
    "hdfs.dump(\"initial content\", \"Resources/somefile.txt\")\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "first_modified = os.path.getmtime(\"somefile.txt\")\n",
    "\n",
    "# Download second time\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "second_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert first_modified == second_modified, \"modified time not matching\"\n",
    "\n",
    "# Content changing on disk\n",
    "hdfs.dump(\"content changed at some point\", \"Resources/somefile.txt\")\n",
    "hdfs_new_content = hdfs.load(\"Resources/somefile.txt\")\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_new_content.decode(\"utf-8\") == local_copied_file, \"third content compare failed\"\n",
    "third_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert not second_modified == third_modified, \"modified time not matching\"\n",
    "\n",
    "# Download last time with overwrite, file should have changed on disk\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"fourth content compare failed\"\n",
    "fourth_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert not third_modified == fourth_modified, \"modified time not matching\"\n",
    "\n",
    "# Download again to make sure overwrite did not cause problems\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"fifth content compare failed\"\n",
    "fifth_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert fourth_modified == fifth_modified, \"modified time not matching\"\n",
    "\n",
    "hdfs.rmr(\"Resources/somefile.txt\")\n",
    "os.remove(\"somefile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Full directory subtree already on local disk and unchanged. Set overwrite=True to force download\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "#copy_to_local directory\n",
    "\n",
    "assert not os.path.exists(\"Resources\")\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "first_modified = os.path.getmtime(\"Resources\")\n",
    "assert os.path.exists(\"Resources\")\n",
    "assert os.path.isdir(\"Resources\")\n",
    "\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "second_modified = os.path.getmtime(\"Resources\")\n",
    "assert first_modified == second_modified\n",
    "\n",
    "localized_dir = hdfs.copy_to_local(\"Resources\", overwrite=True)\n",
    "third_modified = os.path.getmtime(\"Resources\")\n",
    "assert not second_modified == third_modified\n",
    "num_files_first = len(os.listdir(localized_dir))\n",
    "\n",
    "# Add a new file, it should also be localized\n",
    "hdfs.dump(\"a wild file appeared\", \"Resources/newfile.txt\")\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "fourth_modified = os.path.getmtime(\"Resources\")\n",
    "assert first_modified == second_modified\n",
    "num_files_second = len(os.listdir(localized_dir))\n",
    "assert (num_files_first + 1) == num_files_second\n",
    "assert not third_modified == fourth_modified\n",
    "\n",
    "hdfs.rmr(\"Resources/newfile.txt\")\n",
    "shutil.rmtree(\"Resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_md = hdfs.glob(\"Logs/*.md\")\n",
    "logs_path_names = hdfs.lsl(\"Logs/\")\n",
    "if hdfs.exists(\"Logs/test.txt\"):\n",
    "    hdfs.rmr(\"Logs/test.txt\")\n",
    "assert not hdfs.exists(\"Logs/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.dump(\"dummy\", \"Resources/test.txt\")\n",
    "hdfs.cp(\"Resources/test.txt\", \"Logs/\")\n",
    "logs_files = hdfs.ls(\"Logs/\")\n",
    "assert \"test.txt\" in \",\".join(logs_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.mkdir(\"Logs/test_dir\")\n",
    "assert hdfs.exists(\"Logs/test_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_delete = hdfs.ls(\"Logs/\")\n",
    "hdfs.rmr(\"Logs/test_dir\")\n",
    "logs_files_after_delete = hdfs.ls(\"Logs/\")\n",
    "assert len(logs_files_prior_delete) > len(logs_files_after_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" in \",\".join(logs_files_prior_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.move(\"Logs/README_dump_test.md\", \"Logs/README_dump_test2.md\")\n",
    "logs_files_after_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" not in \",\".join(logs_files_after_move)\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_after_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_prior_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.rename(\"Logs/README_dump_test2.md\", \"Logs/README_dump_test.md\")\n",
    "logs_files_after_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"Logs/README_dump_test2.md\" not in \",\".join(logs_files_after_rename)\n",
    "assert \"Logs/README_dump_test.md\" in \",\".join(logs_files_after_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "hdfs.chmod(\"Logs/README.md\", 775)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 775 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.chmod(\"Logs/README.md\", 777)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 777 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_owner = file_stat.st_uid\n",
    "assert hdfs.exists(\"Logs/\")\n",
    "assert not hdfs.exists(\"Not_Existing/neither_am_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.isdir(\"Resources\")\n",
    "assert not hdfs.isdir(\"Resources/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.isfile(\"Resources/README.md\")\n",
    "assert not hdfs.isfile(\"Resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/collect/Resources/my_module.py to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/localized_deps\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "hdfs.dump(\"def simple():\\n\\treturn 5\", \"Resources/my_module.py\")\n",
    "py_path = hdfs.add_module(\"Resources/my_module.py\")\n",
    "assert py_path in sys.path\n",
    "import my_module\n",
    "assert my_module.simple() == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain = hdfs.get_plain_path(\"hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Models/\")\n",
    "assert plain == \"/Projects/demo_deep_learning_admin000/Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.mkdir(\"Logs/test_delete_dir\")\n",
    "assert hdfs.exists(\"Logs/test_delete_dir\")\n",
    "hdfs.delete(\"Logs/test_delete_dir\")\n",
    "assert not hdfs.exists(\"Logs/test_delete_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store Tests\n",
    "\n",
    "These tests require that you have the following files in the Resources directory:\n",
    "\n",
    "- `attendances_features.csv`\n",
    "- `games_features.csv`\n",
    "- `players_features.csv`\n",
    "- `season_scores_features.csv`\n",
    "- `teams_features.csv`\n",
    "\n",
    "These files can be downloaded from here: `http://snurran.sics.se/hops/hops-util-py_test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Create Feature Group Operations (`featurestore.create_featuregroup()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Path does not exist: hdfs://10.0.2.15:8020/Projects/collect/Resources/games_features.csv;'\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 3, in load_fs_sample_data\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/readwriter.py\", line 166, in load\n",
      "    return self._df(self._jreader.load(path))\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: 'Path does not exist: hdfs://10.0.2.15:8020/Projects/collect/Resources/games_features.csv;'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_fs_sample_data():\n",
    "    resources_path = hdfs.project_path() + \"Resources/\"\n",
    "    games_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"games_features.csv\")\n",
    "    players_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"players_features.csv\")\n",
    "    teams_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"teams_features.csv\")\n",
    "    season_scores_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(resources_path + \"season_scores_features.csv\")\n",
    "    attendances_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"attendances_features.csv\")\n",
    "    return games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df\n",
    "games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df = load_fs_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'games_features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'games_features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    games_features_df,\n",
    "    \"games_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'teams_features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'teams_features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_df,\n",
    "    \"teams_features\",\n",
    "    description=\"a spanish version of teams_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'season_scores_features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'season_scores_features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    season_scores_features_df,\n",
    "    \"season_scores_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'attendances_features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'attendances_features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    attendances_features_df,\n",
    "    \"attendances_features\",\n",
    "    description=\"Features of average attendance of games of football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_features_1_df = featurestore.get_featuregroup(\"teams_features\")\n",
    "teams_features_2_df = teams_features_1_df.withColumnRenamed(\n",
    "    \"team_id\", \"equipo_id\").withColumnRenamed(\n",
    "    \"team_budget\", \"equipo_presupuesto\").withColumnRenamed(\n",
    "    \"team_position\", \"equipo_posicion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'teams_features_2_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'teams_features_2_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'teams_features_2_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'teams_features_2_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroup_version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'teams_features_2_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'teams_features_2_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featuregroup_version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "from hops import hdfs\n",
    "query = \"SELECT * FROM games_features_1 WHERE score > 1\"\n",
    "storage_connector = hdfs.project_name() + \"_featurestore\"\n",
    "featuregroup_name = \"games_features_on_demand\"\n",
    "featurestore.create_on_demand_featuregroup(query, featuregroup_name, storage_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert \"games_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"season_scores_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"attendances_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_2\" in featurestore.get_featuregroups()\n",
    "assert \"games_features_on_demand_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Utility Operations, \n",
    "\n",
    "- `featurestore.get_metadata()`,\n",
    "- `featurestore.project_featurestore()`, \n",
    "- `featurestore.get_latest_featuregroup_version()`, \n",
    "- `featurestore.get_features_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hops.featurestore_impl.dao.common.featurestore_metadata.FeaturestoreMetadata object at 0x7fdcf5e3fbe0>"
     ]
    }
   ],
   "source": [
    "featurestore.get_featurestore_metadata(update_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() == hdfs.project_name() + \"_featurestore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() in featurestore.get_project_featurestores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(featurestore.get_project_featurestores()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features_spanish\") == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert \"away_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert \"home_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (hdfs.project_name() + \"_featurestore\", 'JDBC') in featurestore.get_storage_connectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(featurestore.get_storage_connectors()) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read operations of Features and Feature Groups, \n",
    "\n",
    "- `featurestore.get_feature()`, \n",
    "- `featurestore.get_features()`, \n",
    "- `featurestore.get_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 310, in get_feature\n",
      "    jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 372, in _do_get_feature\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 30, in create_logical_plan\n",
      "    self._feature_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 75, in _feature_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\"team_budget\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'teams_features_1'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 310, in get_feature\n",
      "    jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 372, in _do_get_feature\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 30, in create_logical_plan\n",
      "    self._feature_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 66, in _feature_query\n",
      "    self.query.featuregroup_version)\n",
      "KeyError: 'teams_features_1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\n",
    "    \"team_budget\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup=\"teams_features\", \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\"teams_features\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\n",
    "    \"teams_features\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'attendances_features_1.average_attendance' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'attendances_features_1.average_attendance' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"teams_features_1.team_budget\", \"attendances_features_1.average_attendance\"]\n",
    "tmp = featurestore.get_features(features)\n",
    "assert set([\"team_budget\", \"average_attendance\"]) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "descriptor 'intersection' of 'set' object needs an argument\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 130, in _features_query\n",
      "    join_col = query_planner._get_join_col(featuregroups_filtered)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 142, in _get_join_col\n",
      "    common_cols = list(set.intersection(*feature_sets))\n",
      "TypeError: descriptor 'intersection' of 'set' object needs an argument\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'teams_features_1'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 115, in _features_query\n",
      "    for entry in self.query.featuregroups_version_dict]\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 115, in <listcomp>\n",
      "    for entry in self.query.featuregroups_version_dict]\n",
      "KeyError: 'teams_features_1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    },\n",
    "    join_key = \"team_id\",\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'sum_attendance' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'sum_attendance' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\", \"sum_attendance\"\n",
    "    ]\n",
    "tmp = featurestore.get_features(\n",
    "   features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'teams_features_1'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 102, in _features_query\n",
      "    self.query.featuregroups_version_dict[0][constants.REST_CONFIG.JSON_FEATUREGROUP_VERSION]\n",
      "KeyError: 'teams_features_1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"team_id\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featuregroups_version_dict = {\n",
    "        \"teams_features\" : 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Table or view not found: teams_features_1; line 1 pos 31'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 388, in sql\n",
      "    result = core._run_and_log_sql(spark, query)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 396, in _run_and_log_sql\n",
      "    return spark.sql(sql_str)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/session.py\", line 767, in sql\n",
      "    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: 'Table or view not found: teams_features_1; line 1 pos 31'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\n",
    "    \"SELECT team_budget, score \" \\\n",
    "    \"FROM teams_features_1 JOIN games_features_1 ON \" \\\n",
    "    \"games_features_1.home_team_id = teams_features_1.team_id\")\n",
    "features = ['team_budget', 'score']\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 49\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 388, in sql\n",
      "    result = core._run_and_log_sql(spark, query)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 396, in _run_and_log_sql\n",
      "    return spark.sql(sql_str)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/session.py\", line 767, in sql\n",
      "    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 388, in sql\n",
      "    result = core._run_and_log_sql(spark, query)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 396, in _run_and_log_sql\n",
      "    return spark.sql(sql_str)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/session.py\", line 767, in sql\n",
      "    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/hopsdata/tmp/nm-local-dir/usercache/_FeeifJIetMYtCB_6LAfgxXQUl5UEEu7P85ArwnhBaE/appcache/application_1565768877650_0025/container_e02_1565768877650_0025_01_000001/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\",\n",
    "                featurestore=featurestore.project_featurestore(), \n",
    "                 dataframe_type = \"spark\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Test Insert Operations in Existing Feature Groups, `featurestore.insert_into_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "schema = StructType([StructField(\"equipo_id\", IntegerType(), True),\n",
    "                     StructField(\"equipo_presupuesto\", FloatType(), True),\n",
    "                     StructField(\"equipo_posicion\", IntegerType(), True)\n",
    "                        ])\n",
    "sample_df = sqlContext.createDataFrame([(999, 41251.52, 1), (998, 1319.4, 8), (997, 21219.1, 2)], schema)\n",
    "insert_count = sample_df.count()\n",
    "assert insert_count == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spanish_team_features_df = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "pre_insert_count = spanish_team_features_df.count()\n",
    "assert pre_insert_count == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 457, in insert_into_featuregroup\n",
      "    num_clusters=num_clusters)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 487, in _do_insert_into_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\", \n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "spanish_team_features_df_updated = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "\n",
    "after_insert_count = spanish_team_features_df_updated.count()\n",
    "assert after_insert_count == 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 457, in insert_into_featuregroup\n",
      "    num_clusters=num_clusters)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 487, in _do_insert_into_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version=1, \n",
    "    mode=\"append\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False, \n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False, \n",
    "    stat_columns=None, \n",
    "    num_bins=20, \n",
    "    corr_method='pearson',\n",
    "    num_clusters=5\n",
    ")\n",
    "\n",
    "after_insert_count2 = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert after_insert_count2 == 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 457, in insert_into_featuregroup\n",
      "    num_clusters=num_clusters)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 487, in _do_insert_into_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: teams_features_spanish and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "count_after_overwrite = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert count_after_overwrite == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test integration of feature store with Numpy, Pandas and plain Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], dataframe_type=\"pandas\")\n",
    "assert \"team_budget\" in pandas_df.columns.values\n",
    "assert \"average_attendance\" in pandas_df.columns.values\n",
    "assert len(pandas_df) == 50\n",
    "assert len(pandas_df.columns.values) == 2\n",
    "assert isinstance(pandas_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numpy_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"numpy\")\n",
    "assert numpy_df.shape[0] == 50\n",
    "assert numpy_df.shape[1] == 2\n",
    "assert isinstance(numpy_df, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "python_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"python\")\n",
    "assert len(python_df) == 50\n",
    "assert isinstance(python_df, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"spark\")\n",
    "assert spark_df.count() == 50\n",
    "assert isinstance(spark_df, DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'pandas_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'pandas_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's rename the columns to differentiate this feature group from existing ones in the feature store\n",
    "pandas_df.columns = [\"team_budget_test\", \"average_attendance_test\"]\n",
    "\n",
    "featurestore.create_featuregroup(\n",
    "    pandas_df,\n",
    "    \"pandas_test_example\",\n",
    "    description=\"test featuregroup created from pandas dataframe\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"pandas_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: pandas_test_example and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: pandas_test_example and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_pre_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    pandas_df, \n",
    "    \"pandas_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "count_after_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "assert count_pre_pandas_insert_overwrite == count_after_pandas_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'numpy_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'numpy_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    numpy_df,\n",
    "    \"numpy_test_example\",\n",
    "    description=\"test featuregroup created from numpy matrix\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"numpy_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested feature group with name: numpy_test_example and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 266, in get_featuregroup\n",
      "    dataframe_type = dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 695, in _do_get_featuregroup\n",
      "    fg = query_planner._find_featuregroup(featurestore_metadata.featuregroups, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 224, in _find_featuregroup\n",
      "    featuregroup_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: Could not find the requested feature group with name: numpy_test_example and version: 1 among the list of available feature groups: ['games_features_on_demand_1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numpy_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    numpy_df, \n",
    "    \"numpy_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "numpy_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "assert numpy_test_df_count_pre_insert_overwrite == numpy_test_df_count_pre_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'python_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'python_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    python_df,\n",
    "    \"python_test_example\",\n",
    "    description=\"test featuregroup created from python 2D list\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "\n",
    "python_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert \"python_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'python_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'python_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    python_df, \n",
    "    \"python_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "python_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert python_test_df_count_pre_insert_overwrite == python_test_df_count_after_insert_overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Feature Store Statistics `featurestore.update_featuregroup_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in computing the statistics for feature group: teams_features , with version: 1 in featurestore: None. Error: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 528, in update_featuregroup_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.StatisticsComputationError: There was an error in computing the statistics for feature group: teams_features , with version: 1 in featurestore: None. Error: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\"teams_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in computing the statistics for feature group: teams_features , with version: 1 in featurestore: collect_featurestore. Error: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 528, in update_featuregroup_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.StatisticsComputationError: There was an error in computing the statistics for feature group: teams_features , with version: 1 in featurestore: collect_featurestore. Error: 'Table or view not found: teams_features_1; line 1 pos 14'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\n",
    "    \"teams_features\", \n",
    "    featuregroup_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Write Training Dataset Operations \n",
    "\n",
    "- `featurestore.get_latest_training_dataset_version()`\n",
    "- `create_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 357, in get_features\n",
      "    join_key=join_key, dataframe_type=dataframe_type, jdbc_args=jdbc_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 542, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 53, in _find_feature\n",
      "    feature, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNotFound: Could not find the feature with name 'team_budget' in any of the featuregroups of the featurestore: 'collect_featurestore'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = featurestore.get_features(\n",
    "    [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\"]\n",
    ")\n",
    "latest_version = featurestore.get_latest_training_dataset_version(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_csv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"csv\",\n",
    "    training_dataset_version= 1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_tsv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"tsv\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_parquet\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"parquet\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_orc\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"orc\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_avro\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"avro\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_hdf5\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"hdf5\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_npy\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"npy\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'features_df' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'features_df' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Petastorm is only supported in python 3\n",
    "if sys.version_info[0] >= 3:\n",
    "    PetastormSchema = Unischema('team_position_prediction_petastorm_schema', [\n",
    "        UnischemaField('team_budget', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "        UnischemaField('average_attendance', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "        UnischemaField('team_position', np.int32, (), ScalarCodec(IntegerType()), False)\n",
    "    ])\n",
    "\n",
    "    petastorm_args = {\n",
    "        \"schema\": PetastormSchema\n",
    "    }\n",
    "\n",
    "    featurestore.create_training_dataset(\n",
    "        features_df, \"team_position_prediction_petastorm\",\n",
    "        description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "        featurestore=featurestore.project_featurestore(),\n",
    "        data_format=\"petastorm\",\n",
    "        training_dataset_version=1,\n",
    "        descriptive_statistics=False,\n",
    "        feature_correlation=False,\n",
    "        feature_histograms=False,\n",
    "        cluster_analysis=False,\n",
    "        stat_columns=None,\n",
    "        petastorm_args=petastorm_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tds = featurestore.get_training_datasets()\n",
    "assert 'team_position_prediction_1' in tds\n",
    "assert 'team_position_prediction_csv_1' in tds\n",
    "assert 'team_position_prediction_tsv_1' in tds\n",
    "assert 'team_position_prediction_parquet_1' in tds\n",
    "assert 'team_position_prediction_orc_1' in tds\n",
    "assert 'team_position_prediction_avro_1' in tds\n",
    "assert 'team_position_prediction_hdf5_1'in tds\n",
    "assert 'team_position_prediction_npy_1' in tds\n",
    "if sys.version_info[0] >= 3:\n",
    "    assert 'team_position_prediction_petastorm_1' in tds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Insert into an existing training dataset, `featurestore.insert_into_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_pre_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "featurestore.insert_into_training_dataset(\n",
    "    features_df, \n",
    "    \"team_position_prediction_csv\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version=featurestore.get_latest_training_dataset_version(\"team_position_prediction_csv\")\n",
    ")\n",
    "count_after_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "assert count_pre_insert == count_after_insert # td only support overwrites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Training Dataset Utility Methods\n",
    "\n",
    "- `featurestore.get_training_dataset_path()`\n",
    "- `featurestore.get_training_dataset_tf_record_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1084, in get_training_dataset_path\n",
      "    training_dataset_version=training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1168, in _do_get_training_dataset_path\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert hdfs.project_path() in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1084, in get_training_dataset_path\n",
      "    training_dataset_version=training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1168, in _do_get_training_dataset_path\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert hdfs.project_name() + \"_Training_Datasets\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1084, in get_training_dataset_path\n",
      "    training_dataset_version=training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1168, in _do_get_training_dataset_path\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert \"team_position_prediction_csv\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 836, in get_training_dataset_tf_record_schema\n",
      "    featurestore=featurestore)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1201, in _do_get_training_dataset_tf_record_schema\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_schema = featurestore.get_training_dataset_tf_record_schema(\"team_position_prediction\")\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = featurestore.get_training_dataset(\"team_position_prediction\")\n",
    "tf_schema = featurestore.get_dataframe_tf_record_schema(features_df)\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Training Dataset stats\n",
    "\n",
    "- `featurestore.update_training_dataset_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in computing the statistics for training dataset: team_position_prediction , with version: 1 in featurestore: None. Error: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1212, in update_training_dataset_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.StatisticsComputationError: There was an error in computing the statistics for training dataset: team_position_prediction , with version: 1 in featurestore: None. Error: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in computing the statistics for training dataset: team_position_prediction , with version: 1 in featurestore: collect_featurestore. Error: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1212, in update_training_dataset_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.StatisticsComputationError: There was an error in computing the statistics for training dataset: team_position_prediction , with version: 1 in featurestore: collect_featurestore. Error: Could not find the requested training dataset with name: team_position_prediction and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\n",
    "    \"team_position_prediction\", \n",
    "    training_dataset_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read Training Datasets API `featurestore.get_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_csv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['team_budget', 'average_attendance', 'team_position']\n",
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_csv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_hdf5 and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_hdf5 and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_hdf5\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_petastorm and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_petastorm and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if sys.version_info[0] >= 3:\n",
    "    tmp = featurestore.get_training_dataset(\"team_position_prediction_petastorm\")\n",
    "    assert set(tmp.columns) == set(cols)\n",
    "    assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_avro and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_avro and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_avro\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_orc and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_orc and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_orc\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_tsv and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_tsv and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_tsv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_npy and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_npy and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_npy\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the requested training dataset with name: team_position_prediction_parquet and version: 1 among the list of available training datasets: []\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 868, in get_training_dataset\n",
      "    dataframe_type=dataframe_type)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 756, in _do_get_training_dataset\n",
      "    training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 196, in _find_training_dataset\n",
      "    training_dataset_names))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: Could not find the requested training dataset with name: team_position_prediction_parquet and version: 1 among the list of available training datasets: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_parquet\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Get Statistics\n",
    "\n",
    "- `featurestore.get_featuregroup_statistics()`\n",
    "- `featurestore.get_training_dataset_statistics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1787, in get_featuregroup_statistics\n",
      "    return core._do_get_featuregroup_statistics(featuregroup_name, featurestore, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1534, in _do_get_featuregroup_statistics\n",
      "    featuregroup_id = _get_featuregroup_id(featurestore, featuregroup_name, featuregroup_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 309, in _get_featuregroup_id\n",
      "    featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeaturegroupNotFound: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = featurestore.get_featuregroup_statistics(\"teams_features\")\n",
    "assert not stats.cluster_analysis is None\n",
    "assert not stats.cluster_analysis.clusters is None\n",
    "assert not stats.cluster_analysis.datapoints is None\n",
    "assert len(stats.cluster_analysis.clusters) == len(stats.cluster_analysis.datapoints)\n",
    "assert not stats.cluster_analysis.clusters[0].datapoint_name is None\n",
    "assert not stats.cluster_analysis.clusters[0].cluster is None\n",
    "assert not stats.correlation_matrix is None\n",
    "assert not stats.correlation_matrix.feature_correlations is None\n",
    "assert len(stats.correlation_matrix.feature_correlations) > 0\n",
    "assert len(stats.correlation_matrix.feature_correlations) < constants.FEATURE_STORE.MAX_CORRELATION_MATRIX_COLUMNS\n",
    "assert not stats.correlation_matrix.feature_correlations[0].feature_name is None\n",
    "assert not stats.correlation_matrix.feature_correlations[0].correlation_values is None\n",
    "assert len(stats.correlation_matrix.feature_correlations[0].correlation_values) == \\\n",
    "len(stats.correlation_matrix.feature_correlations)\n",
    "assert not stats.descriptive_stats is None\n",
    "assert not stats.descriptive_stats.descriptive_stats is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].feature_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats[0].metric_values) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].metric_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].value is None\n",
    "assert not stats.feature_histograms is None\n",
    "assert not stats.feature_histograms.feature_distributions is None\n",
    "assert len(stats.feature_histograms.feature_distributions) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].feature_name is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution is None\n",
    "assert len(stats.feature_histograms.feature_distributions[0].frequency_distribution) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].bin is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].frequency is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1815, in get_training_dataset_statistics\n",
      "    return core._do_get_training_dataset_statistics(training_dataset_name, featurestore, training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1557, in _do_get_training_dataset_statistics\n",
      "    training_dataset_id = _get_training_dataset_id(featurestore, training_dataset_name, training_dataset_version)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1120, in _get_training_dataset_id\n",
      "    training_dataset_name, training_dataset_version, featurestore))\n",
      "hops.featurestore_impl.exceptions.exceptions.TrainingDatasetNotFound: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = featurestore.get_training_dataset_statistics(\"team_position_prediction\")\n",
    "assert not stats.cluster_analysis is None\n",
    "assert not stats.cluster_analysis.clusters is None\n",
    "assert not stats.cluster_analysis.datapoints is None\n",
    "assert len(stats.cluster_analysis.clusters) == len(stats.cluster_analysis.datapoints)\n",
    "assert not stats.cluster_analysis.clusters[0].datapoint_name is None\n",
    "assert not stats.cluster_analysis.clusters[0].cluster is None\n",
    "assert not stats.correlation_matrix is None\n",
    "assert not stats.correlation_matrix.feature_correlations is None\n",
    "assert len(stats.correlation_matrix.feature_correlations) > 0\n",
    "assert len(stats.correlation_matrix.feature_correlations) < constants.FEATURE_STORE.MAX_CORRELATION_MATRIX_COLUMNS\n",
    "assert not stats.correlation_matrix.feature_correlations[0].feature_name is None\n",
    "assert not stats.correlation_matrix.feature_correlations[0].correlation_values is None\n",
    "assert len(stats.correlation_matrix.feature_correlations[0].correlation_values) == len(stats.correlation_matrix.feature_correlations)\n",
    "assert not stats.descriptive_stats is None\n",
    "assert not stats.descriptive_stats.descriptive_stats is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].feature_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats[0].metric_values) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].metric_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].value is None\n",
    "assert not stats.feature_histograms is None\n",
    "assert not stats.feature_histograms.feature_distributions is None\n",
    "assert len(stats.feature_histograms.feature_distributions) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].feature_name is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution is None\n",
    "assert len(stats.feature_histograms.feature_distributions[0].frequency_distribution) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].bin is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].frequency is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Visualizations\n",
    "\n",
    "- `featurestore.visualize_featuregroup_distributions()`\n",
    "- `featurestore.visualize_featuregroup_correlations()`\n",
    "- `featurestore.visualize_featuregroup_clusters()`\n",
    "- `featurestore.visualize_featuregroup_descriptive_stats()`\n",
    "- `featurestore.visualize_training_dataset_distributions()`\n",
    "- `featurestore.visualize_training_dataset_correlations()`\n",
    "- `featurestore.visualize_traniing_dataset_clusters()`\n",
    "- `featurestore.visualize_training_dataset_descriptive_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature distributions for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1317, in visualize_featuregroup_distributions\n",
      "    featuregroup_name, featuregroup_version, featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature distributions for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_featuregroup_distributions(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature correlations for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1391, in visualize_featuregroup_correlations\n",
      "    featuregroup_name, featuregroup_version, featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature correlations for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_featuregroup_correlations(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature clusters for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1455, in visualize_featuregroup_clusters\n",
      "    featuregroup_name, featuregroup_version, featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature clusters for feature group: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_featuregroup_clusters(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the descriptive statistics for featuregroup: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1499, in visualize_featuregroup_descriptive_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the descriptive statistics for featuregroup: teams_features with version: 1 in featurestore: collect_featurestore. Error: The featuregroup teams_features with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc_stats_df = featurestore.visualize_featuregroup_descriptive_stats(\"teams_features\")\n",
    "desc_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature distributions for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1573, in visualize_training_dataset_distributions\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature distributions for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_training_dataset_distributions(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature correlations for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1650, in visualize_training_dataset_correlations\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature correlations for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_training_dataset_correlations(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the feature clusters for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1715, in visualize_training_dataset_clusters\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the feature clusters for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = featurestore.visualize_training_dataset_clusters(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in visualizing the descriptive statistics for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/featurestore.py\", line 1759, in visualize_training_dataset_descriptive_stats\n",
      "    featurestore, str(e)))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureVisualizationError: There was an error in visualizing the descriptive statistics for training dataset: team_position_prediction with version: 1 in featurestore: collect_featurestore. Error: The training dataset team_position_prediction with version: 1 was not found in the feature store collect_featurestore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc_stats_df = featurestore.visualize_training_dataset_descriptive_stats(\"team_position_prediction\")\n",
    "desc_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleanup (Delete FS Contents so that next test run works the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete feature groups\n",
    "spark.sql('use ' + featurestore.project_featurestore())\n",
    "for fg in featurestore.get_featuregroups():\n",
    "    try:\n",
    "        spark.sql(\"drop table \" + fg)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete training datasets\n",
    "td_dir = hdfs.project_name() + \"_Training_Datasets/\"\n",
    "for td in featurestore.get_training_datasets():\n",
    "    try:\n",
    "        hdfs.rmr(td_dir + td)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.get_featurestore_metadata(update_cache=True)\n",
    "# on demand feature group will still be there.. maybe add delete endpoint in the python SDK?\n",
    "#assert featurestore.get_featuregroups() == [] \n",
    "assert featurestore.get_training_datasets() == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test default config \n",
    "\n",
    "- `kafka.get_default_config()`, \n",
    "- `kafka.get_security_protocol()`,\n",
    "- `kafka.get_broker_endpoints_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = kafka.get_kafka_default_config()\n",
    "assert \"bootstrap.servers\" in config\n",
    "assert \"security.protocol\" in config\n",
    "assert \"ssl.ca.location\" in config\n",
    "assert \"ssl.key.location\" in config\n",
    "assert \"ssl.certificate.location\" in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(kafka.get_security_protocol()) > 0\n",
    "assert len(kafka.get_broker_endpoints_list()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test access to TLS tokens\n",
    "\n",
    "- `tls.get_key_store()`\n",
    "- `tls.get_trust_store()`\n",
    "- `tls.get_key_store_pwd()`\n",
    "- `tls.get_trust_store_pwd()`\n",
    "- `tls.get_client_certificate_location()`\n",
    "- `tls.get_client_key_location()`\n",
    "- `tls.get_ca_chain_location()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tls.get_key_store()) > 0\n",
    "assert len(tls.get_trust_store()) > 0\n",
    "assert len(tls.get_key_store_pwd()) > 0\n",
    "assert len(tls.get_trust_store_pwd()) > 0\n",
    "assert len(tls.get_client_certificate_location()) > 0\n",
    "assert len(tls.get_client_key_location()) > 0\n",
    "assert len(tls.get_ca_chain_location()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Tests\n",
    "\n",
    "These tests require that you have the following files in the Resources directory:\n",
    "\n",
    "- `iris_model.knn`\n",
    "- `iris_flower_classifier.py`\n",
    "- `mnist`\n",
    "\n",
    "Where mnist is a directory containing a tensorflow model.\n",
    "\n",
    "These files can be downloaded from here: `http://snurran.sics.se/hops/hops-util-py_test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the provided model_path: Resources/iris_knn.pkl , does not exist in HDFS or on the local filesystem\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 404, in export\n",
      "    model_path))\n",
      "ValueError: the provided model_path: Resources/iris_knn.pkl , does not exist in HDFS or on the local filesystem\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Resources/iris_knn.pkl\"\n",
    "serving.export(model_path, \"IrisFlowerClassifier\", 1, overwrite=True)\n",
    "assert hdfs.exists(\"Models/IrisFlowerClassifier/1/iris_knn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the provided model_path: Resources/iris_flower_classifier.py , does not exist in HDFS or on the local filesystem\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 404, in export\n",
      "    model_path))\n",
      "ValueError: the provided model_path: Resources/iris_flower_classifier.py , does not exist in HDFS or on the local filesystem\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Resources/iris_flower_classifier.py\"\n",
    "serving.export(model_path, \"IrisFlowerClassifier\", 1, overwrite=True)\n",
    "assert hdfs.exists(\"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the provided model_path: Resources/mnist/ , does not exist in HDFS or on the local filesystem\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 404, in export\n",
      "    model_path))\n",
      "ValueError: the provided model_path: Resources/mnist/ , does not exist in HDFS or on the local filesystem\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Resources/mnist/\"\n",
    "serving.export(model_path, \"mnist\", 2, overwrite=True)\n",
    "assert hdfs.exists(\"Models/mnist/2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Serve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "path hdfs://10.0.2.15:8020/Projects/collect/Models/IrisFlowerClassifier/1/iris_flower_classifier.py not found\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 223, in create_or_update\n",
      "    artifact_path = hdfs._expand_path(artifact_path)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/hdfs.py\", line 135, in _expand_path\n",
      "    raise IOError(\"path %s not found\" % hdfs_path)\n",
      "OSError: path hdfs://10.0.2.15:8020/Projects/collect/Models/IrisFlowerClassifier/1/iris_flower_classifier.py not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "script_path = \"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\"\n",
    "if serving.exists(\"IrisFlowerClassifier\"):\n",
    "    serving.delete(\"IrisFlowerClassifier\")\n",
    "serving.create_or_update(script_path, \"IrisFlowerClassifier\", serving_type=\"SKLEARN\", \n",
    "                                 model_version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert serving.exists(\"IrisFlowerClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "path hdfs://10.0.2.15:8020/Projects/collect/Models/mnist/2/ not found\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 223, in create_or_update\n",
      "    artifact_path = hdfs._expand_path(artifact_path)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/hdfs.py\", line 135, in _expand_path\n",
      "    raise IOError(\"path %s not found\" % hdfs_path)\n",
      "OSError: path hdfs://10.0.2.15:8020/Projects/collect/Models/mnist/2/ not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/mnist/2/\"\n",
    "if serving.exists(\"mnist\"):\n",
    "    serving.delete(\"mnist\")\n",
    "serving.create_or_update(model_path, \"mnist\", serving_type=\"TENSORFLOW\", \n",
    "                                 model_version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert serving.exists(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Data Access Operations on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 507, in get_id\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert serving.get_id(\"IrisFlowerClassifier\") is not None\n",
    "assert serving.get_id(\"mnist\") is not None\n",
    "assert \"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\" in serving.get_artifact_path(\"IrisFlowerClassifier\")\n",
    "assert \"Models/mnist/2/\" in serving.get_artifact_path(\"mnist\")\n",
    "assert serving.get_type(\"IrisFlowerClassifier\") == \"SKLEARN\"\n",
    "assert serving.get_type(\"mnist\") == \"TENSORFLOW\"\n",
    "assert serving.get_version(\"IrisFlowerClassifier\") == 1\n",
    "assert serving.get_version(\"mnist\") == 2\n",
    "assert serving.get_kafka_topic(\"IrisFlowerClassifier\") is not None\n",
    "assert serving.get_kafka_topic(\"mnist\") is not None\n",
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Stopped\"\n",
    "assert serving.get_status(\"mnist\") == \"Stopped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Start/Stop Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 123, in start\n",
      "    serving_id = get_id(serving_name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 507, in get_id\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving.start(\"IrisFlowerClassifier\")\n",
    "serving.start(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 607, in get_status\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Running\"\n",
    "assert serving.get_status(\"mnist\") == \"Running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 144, in stop\n",
      "    serving_id = get_id(serving_name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 507, in get_id\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving.stop(\"IrisFlowerClassifier\")\n",
    "serving.stop(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 607, in get_status\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Stopped\"\n",
    "assert serving.get_status(\"mnist\") == \"Stopped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Send Inference Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 123, in start\n",
      "    serving_id = get_id(serving_name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 507, in get_id\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving.start(\"IrisFlowerClassifier\")\n",
    "serving.start(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/IrisFlowerClassifier:predict), server response: \n",
      " HTTP code: 404, HTTP reason: Not Found, error code: 250000, error msg: Serving instance not found, user msg: name: IrisFlowerClassifier\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 721, in make_inference_request\n",
      "    return _make_inference_request_rest(serving_name, data, verb)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 759, in _make_inference_request_rest\n",
      "    error_code, error_msg, user_msg))\n",
      "hops.exceptions.RestAPIError: Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/IrisFlowerClassifier:predict), server response: \n",
      " HTTP code: 404, HTTP reason: Not Found, error code: 250000, error msg: Serving instance not found, user msg: name: IrisFlowerClassifier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    data = {\"inputs\" : [[random.uniform(1, 8) for i in range(4)]]}\n",
    "    response = serving.make_inference_request(\"IrisFlowerClassifier\", data)\n",
    "    assert response is not None\n",
    "    assert \"predictions\" or \"prediction\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/mnist:predict), server response: \n",
      " HTTP code: 404, HTTP reason: Not Found, error code: 250000, error msg: Serving instance not found, user msg: name: mnist\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 721, in make_inference_request\n",
      "    return _make_inference_request_rest(serving_name, data, verb)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 759, in _make_inference_request_rest\n",
      "    error_code, error_msg, user_msg))\n",
      "hops.exceptions.RestAPIError: Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/mnist:predict), server response: \n",
      " HTTP code: 404, HTTP reason: Not Found, error code: 250000, error msg: Serving instance not found, user msg: name: mnist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    data = {\n",
    "                \"signature_name\": 'predict_images',\n",
    "                \"instances\": [np.random.rand(784).tolist()]\n",
    "            }\n",
    "    response = serving.make_inference_request(\"mnist\", data)\n",
    "    assert response is not None\n",
    "    assert \"predictions\" in response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Kafka Inference Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avro Python is only supported in python 2\n",
    "if sys.version_info[0] < 3:\n",
    "    topic = serving.get_kafka_topic(\"IrisFlowerClassifier\")\n",
    "    config = kafka.get_kafka_default_config()\n",
    "    config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "    consumer = Consumer(config)\n",
    "    topics = [topic]\n",
    "    consumer.subscribe(topics)\n",
    "    json_schema = kafka.get_schema(topic)\n",
    "    avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avro Python is only supported in python 2\n",
    "if sys.version_info[0] < 3:\n",
    "    for i in range(0, 10):\n",
    "        msg = consumer.poll(timeout=1.5)\n",
    "        if msg is not None:\n",
    "            value = msg.value()\n",
    "            event_dict = kafka.parse_avro_msg(value, avro_schema)\n",
    "            assert \"modelName\" in event_dict\n",
    "            assert \"requestTimestamp\" in event_dict\n",
    "            assert \"servingType\" in event_dict\n",
    "            assert \"inferenceResponse\" in event_dict\n",
    "            assert event_dict[\"modelName\"] == \"IrisFlowerClassifier\"\n",
    "            assert event_dict[\"servingType\"] == \"SKLEARN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avro Python is only supported in python 2\n",
    "if sys.version_info[0] < 3:\n",
    "    topic = serving.get_kafka_topic(\"mnist\")\n",
    "    config = kafka.get_kafka_default_config()\n",
    "    config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "    consumer = Consumer(config)\n",
    "    topics = [topic]\n",
    "    consumer.subscribe(topics)\n",
    "    json_schema = kafka.get_schema(topic)\n",
    "    avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avro Python is only supported in python 2\n",
    "if sys.version_info[0] < 3:\n",
    "    for i in range(0, 10):\n",
    "        msg = consumer.poll(timeout=1.5)\n",
    "        if msg is not None:\n",
    "            value = msg.value()\n",
    "            event_dict = kafka.parse_avro_msg(value, avro_schema)\n",
    "            assert \"modelName\" in event_dict\n",
    "            assert \"requestTimestamp\" in event_dict\n",
    "            assert \"servingType\" in event_dict\n",
    "            assert \"inferenceResponse\" in event_dict\n",
    "            assert event_dict[\"modelName\"] == \"mnist\"\n",
    "            assert event_dict[\"servingType\"] == \"TENSORFLOW\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Delete Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 57, in delete\n",
      "    serving_id = get_id(serving_name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 507, in get_id\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 648, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: IrisFlowerClassifier could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "serving.delete(\"IrisFlowerClassifier\")\n",
    "serving.delete(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No serving with name IrisFlowerClassifier was found in the project collect\n",
      "No serving with name mnist was found in the project collect"
     ]
    }
   ],
   "source": [
    "assert not serving.exists(\"IrisFlowerClassifier\")\n",
    "assert not serving.exists(\"mnist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}